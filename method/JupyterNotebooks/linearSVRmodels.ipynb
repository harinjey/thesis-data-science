{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVR: Default & Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn import svm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "frag = pd.read_csv(\"/mnt/project/Transpose/hidra/results/salmon-hidra/batch1/fragment_filtered_fasta/filtered_fragments.fasta\", sep=\"\\t\", header= None,  names=[\"fragment_id\", \"sequence\"])\n",
    "\n",
    "deseq = pd.read_csv(\"/mnt/project/Transpose/hidra/results/salmon-hidra/batch1/DESeq_TSV/DESeq_res.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data for n nucleotides\n",
    "frag = frag.loc[~frag['sequence'].str.contains('n')].reset_index()\n",
    "frag.drop(\"index\", axis=1)\n",
    "\n",
    "deseq = deseq.drop(labels = [2634852, 2634853, 2634854, 2634855, 2634856]).reset_index()\n",
    "deseq = deseq.drop(\"index\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non significant values are given 1 as pvalue and padj\n",
    "\n",
    "not_sig = {\"pvalue\": 1, \"padj\":1}\n",
    "\n",
    "deseq = deseq.fillna(value=not_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating frag and deseq tables to one table\n",
    "df_all_cols = pd.concat([frag, deseq ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting fragments from chromosome 21 and 25 form the table and create a dataframe with only those as test set\n",
    "chrom_21 = df_all_cols[df_all_cols['fragment'].str.contains('21:')]\n",
    "\n",
    "chrom_25 = df_all_cols[df_all_cols['fragment'].str.contains('25:')]\n",
    "\n",
    "test_set = pd.concat([chrom_21, chrom_25], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training set of all fragments except fragments from chromosome 21 and 25\n",
    "df_training = df_all_cols.loc[~df_all_cols[\"fragment\"].str.contains('25:') & ~df_all_cols[\"fragment\"].str.contains('21:')].reset_index()\n",
    "df_training.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fragments within top 10% basemean for both training and test sets\n",
    "\n",
    "filtered_frag = df_training[df_training[\"baseMean\"] > 62.609201]\n",
    "\n",
    "filtered_test = test_set[test_set[\"baseMean\"] > 65.333982]\n",
    "\n",
    "# Extracting the log2FoldChange values (true values) from training set and test set\n",
    "y_test = (filtered_test.log2FoldChange)\n",
    "y = (filtered_frag.log2FoldChange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-mer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_mer function to create k-mer features\n",
    "# k-mer function modified from: https://www.kaggle.com/code/mohdmuttalib/biological-sequence-modeling-with-k-mer-features\n",
    "def getKmers(sequence, size):\n",
    "    kmer_seq= [sequence[x:x+size].upper() for x in range(len(sequence) - size + 1)]\n",
    "    return ' '.join(kmer_seq)\n",
    "#from list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply k-mer encoding with k-mer sizes from 2 to 6 for each fragment in test set\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "filtered_test[\"kmer_2\"] = filtered_test[\"sequence\"].apply(lambda x: getKmers(x, size=2))\n",
    "kmer2test = vectorizer.fit_transform(filtered_test['kmer_2']).astype('float32')\n",
    "kmer_2test = np.asarray(kmer2test/kmer2test.sum(axis=1))\n",
    "kmer2_testdf = pd.DataFrame(kmer_2test,columns=['2_mer'] * (4**2))\n",
    "\n",
    "filtered_test[\"kmer_3\"] = filtered_test[\"sequence\"].apply(lambda x: getKmers(x, size=3))\n",
    "kmer3test = vectorizer.fit_transform(filtered_test['kmer_3']).astype('float32')\n",
    "kmer_3test = np.asarray(kmer3test/kmer3test.sum(axis=1))\n",
    "kmer3_testdf = pd.DataFrame(kmer_3test,columns=['3_mer'] * (4**3))\n",
    "\n",
    "filtered_test[\"kmer_4\"] = filtered_test[\"sequence\"].apply(lambda x: getKmers(x, size=4))\n",
    "kmer4test = vectorizer.fit_transform(filtered_test['kmer_4']).astype('float32')\n",
    "kmer_4test = np.asarray(kmer4test/kmer4test.sum(axis=1))\n",
    "kmer4_testdf = pd.DataFrame(kmer_4test,columns=['4_mer'] * (4**4))\n",
    "\n",
    "filtered_test[\"kmer_5\"] = filtered_test[\"sequence\"].apply(lambda x: getKmers(x, size=5))\n",
    "kmer5test = vectorizer.fit_transform(filtered_test['kmer_5']).astype('float32')\n",
    "kmer_5test = np.asarray(kmer5test/kmer5test.sum(axis=1))\n",
    "kmer5_testdf = pd.DataFrame(kmer_5test,columns=['5_mer'] * (4**5))\n",
    "\n",
    "filtered_test[\"kmer_6\"] = filtered_test[\"sequence\"].apply(lambda x: getKmers(x, size=6))\n",
    "kmer6test = vectorizer.fit_transform(filtered_test['kmer_6']).astype('float32')\n",
    "kmer_6test = np.asarray(kmer6test/kmer6test.sum(axis=1))\n",
    "kmer6_testdf = pd.DataFrame(kmer_6test,columns=['6_mer'] * (4**6))\n",
    "\n",
    "X_test = pd.concat([kmer2_testdf, kmer3_testdf, kmer4_testdf, kmer5_testdf, kmer6_testdf], axis = 1)\n",
    "\n",
    "X_test= np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k-mer features for training set\n",
    "vectorizer2 = CountVectorizer()\n",
    "filtered_frag[\"kmer_2\"] = filtered_frag[\"sequence\"].apply(lambda x: getKmers(x, size=2))\n",
    "kmer2 = vectorizer2.fit_transform(filtered_frag['kmer_2']).astype('float32')\n",
    "kmer_2 = np.asarray(kmer2/kmer2.sum(axis=1))\n",
    "kmer2_df = pd.DataFrame(kmer_2,columns=['2_mer'] * (4**2))\n",
    "feature_names1 = vectorizer2.get_feature_names_out()\n",
    "\n",
    "\n",
    "vectorizer3 = CountVectorizer()\n",
    "filtered_frag[\"kmer_3\"] = filtered_frag[\"sequence\"].apply(lambda x: getKmers(x, size=3))\n",
    "kmer3 = vectorizer3.fit_transform(filtered_frag['kmer_3']).astype('float32')\n",
    "kmer_3 = np.asarray(kmer3/kmer3.sum(axis=1))\n",
    "kmer3_df = pd.DataFrame(kmer_3,columns=['3_mer'] * (4**3))\n",
    "feature_names2 = vectorizer3.get_feature_names_out()\n",
    "\n",
    "vectorizer4 = CountVectorizer()\n",
    "filtered_frag[\"kmer_4\"] = filtered_frag[\"sequence\"].apply(lambda x: getKmers(x, size=4))\n",
    "kmer4 = vectorizer4.fit_transform(filtered_frag['kmer_4']).astype('float32')\n",
    "kmer_4 = np.asarray(kmer4/kmer4.sum(axis=1))\n",
    "kmer4_df = pd.DataFrame(kmer_4,columns=['4_mer'] * (4**4))\n",
    "feature_names3 = vectorizer4.get_feature_names_out()\n",
    "\n",
    "vectorizer5 = CountVectorizer()\n",
    "filtered_frag[\"kmer_5\"] = filtered_frag[\"sequence\"].apply(lambda x: getKmers(x, size=5))\n",
    "kmer5 = vectorizer5.fit_transform(filtered_frag['kmer_5']).astype('float32')\n",
    "kmer_5 = np.asarray(kmer5/kmer5.sum(axis=1))\n",
    "kmer5_df = pd.DataFrame(kmer_5,columns=['5_mer'] * (4**5))\n",
    "feature_names4 = vectorizer5.get_feature_names_out()\n",
    "\n",
    "vectorizer6 = CountVectorizer()\n",
    "filtered_frag[\"kmer_6\"] = filtered_frag[\"sequence\"].apply(lambda x: getKmers(x, size=6))\n",
    "kmer6 = vectorizer6.fit_transform(filtered_frag['kmer_6']).astype('float32')\n",
    "kmer_6 = np.asarray(kmer6/kmer6.sum(axis=1))\n",
    "kmer6_df = pd.DataFrame(kmer_6,columns=['6_mer'] * (4**6))\n",
    "feature_names5 = vectorizer6.get_feature_names_out()\n",
    "\n",
    "\n",
    "X = pd.concat([kmer2_df, kmer3_df, kmer4_df, kmer5_df, kmer6_df], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature names to use for feature importance\n",
    "feature_names = []\n",
    "feature_names.extend(feature_names1)\n",
    "feature_names.extend(feature_names2)\n",
    "feature_names.extend(feature_names3)\n",
    "feature_names.extend(feature_names4)\n",
    "feature_names.extend(feature_names5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names as list \n",
    "X_names = list(X.columns)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validation split\n",
    "X_train,X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model Linear Support Vector Regression model with default parameter\n",
    "linearsvr = svm.LinearSVR(random_state=42)\n",
    "# Train the model\n",
    "linearsvr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = linearsvr.predict(X_valid)\n",
    "\n",
    "# Calculatig root mean squared error\n",
    "rmse_pred = mean_squared_error(y_valid, y_pred) \n",
    "\n",
    "print(\"Root Mean Squared Error:\" , np.sqrt(rmse_pred))\n",
    "\n",
    "print(\"R2 score:\" , r2_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set \n",
    "y_pred_test = linearsvr.predict(X_test)\n",
    "\n",
    "print(\"R2 score test:\" ,r2_score(y_test, y_pred_test))\n",
    "\n",
    "rmse_pred_test = mean_squared_error(y_test, y_pred_test) \n",
    "\n",
    "print(\"Root Mean Squared Error:\" , np.sqrt(rmse_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'epsilon': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "              }\n",
    "\n",
    "\n",
    "# scoring metric\n",
    "scoring_metric = 'r2'\n",
    "\n",
    "# Grid search\n",
    "linear_svr = svm.LinearSVR()\n",
    "grid_search = GridSearchCV(linear_svr, params_grid, scoring=scoring_metric, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tuned model\n",
    "import joblib\n",
    "filename = \"svr_tuned.joblib\"\n",
    "joblib.dump(grid_search.best_estimator_, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best parameters\n",
    "reg_sgd = grid_search.best_estimator_\n",
    "print(grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on validation set\n",
    "y_pred = reg_sgd.predict(X_valid)\n",
    "\n",
    "# Calculatig root mean squared error\n",
    "rmse_pred = mean_squared_error(y_valid, y_pred) \n",
    "\n",
    "print(\"Root Mean Squared Error Validation:\" , np.sqrt(rmse_pred))\n",
    "\n",
    "print(\"R2 score Val:\" , r2_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set \n",
    "y_pred_test = reg_sgd.predict(X_test)\n",
    "\n",
    "print(\"R2 score test:\" ,r2_score(y_test, y_pred_test))\n",
    "\n",
    "rmse_pred_test = mean_squared_error(y_test, y_pred_test) \n",
    "\n",
    "print(\"Root Mean squared Error Test:\" , np.sqrt(rmse_pred_test))\n",
    "\n",
    "print(np.corrcoef(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.corrcoef(y_test,y_pred_test))\n",
    "\n",
    "r = np.corrcoef(y_test.T, y_pred_test.T)[0, 1]\n",
    "\n",
    "# Plot the true vs predicted values \n",
    "plt.scatter(y_test, y_pred_test, alpha=0.5)\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title('True vs. Predicted Values')\n",
    "plt.savefig(\"svr_tunednormal.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a scatter histogram\n",
    "plt.hist2d(y_test, y_pred_test, bins=100, cmap='viridis',cmin=1)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title('True vs. Predicted Values')\n",
    "plt.savefig(\"svrtuned.png\")\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterHarini",
   "language": "python",
   "name": "masterharini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
